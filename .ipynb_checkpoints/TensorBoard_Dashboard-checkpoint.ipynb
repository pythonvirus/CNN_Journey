{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">TensorBoard Overview</font>\n",
    "\n",
    "### <font style=\"color:green\">What is TensorBoard?</font>\n",
    "TensorBoard is a visualization toolkit for machine learning experimentations. It has the following features:\n",
    "\n",
    "    * Tracking and visualizing metrics such as loss and accuracy\n",
    "\n",
    "    * Visualizing the model graph (operations and layers)\n",
    "\n",
    "    * Viewing histograms of weights, biases, or other tensors as they change over time.\n",
    "\n",
    "    * Projecting embeddings to a lower-dimensional space - it gives a visual reprsentation of how the model classifies different instances of objects\n",
    "\n",
    "    * Displaying images, text, and audio data\n",
    "\n",
    "    * And much more, get more details here\n",
    "\n",
    "### <font style=\"color:green\">Why do we need TensorBoard?</font>\n",
    "\n",
    "    A good model demands a lot of experiments. For example, to get to the best model, we need to perform hyperparameter tuning, trying different models, trying different regularization techniques, etc. It can become cumbersome to track and remember what you did/achieved in older experiments.\n",
    "\n",
    "    We know that getting insights into visual logs is much easier as compared to text logs. Since deep learning training takes longer time than usual, it is not very easy to monitor text logs. You should ideally keep the training running and work on something else. Once the training is over, you can check the logs to get insights about how the model trained.\n",
    "\n",
    "    Till now we were using MatPlotLib to get visual insights. While using MatPlotLib does a good job in plotting the curves, there are many more features in Tensorboard (mentioned above) which can come in handy if your model is not behaving \"nicely\".\n",
    "\n",
    "Organizing training logs is not an easy task. But, **TensorBoard solves all these problems.**\n",
    "\n",
    "**In this section, we will see how to:**\n",
    "\n",
    "        * Set up Tensorboard.\n",
    "\n",
    "        * Write logs to Tensorboard.\n",
    "\n",
    "        * Get model insights using Tensorboard.\n",
    "\n",
    "        * Visualize data embeddings (2-d or 3-d) using TensorBoard. Data embedding is an effective way to dimensionality reduction (e.g., T-SNE, PCA, etc.).\n",
    "\n",
    "        * Get a histogram plot of model weights using TensorBoard ( this can be used to debug overfitting ).\n",
    "\n",
    "        * Add images to TensorBoard.\n",
    "\n",
    "        * Get Precision and Recall curves using TensorBoard.\n",
    "\n",
    "        * Display TensorBoard UI in Jupyter Notebook.\n",
    "\n",
    "        * Display TensorBoard UI using a browser - (a) TensorBoard running remotely, and (b) TensorBoard running locally.\n",
    "\n",
    "        * Share your TensorBoard dashboard (logs) using TensorBoard.dev.\n",
    "\n",
    "        * We will start with the TensorBoard Dashboard display and end with sharing logs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">TensorBoard Dashboard</font>\n",
    "Let us get started with using Tensorboard. Since there are a lot of features provided by Tensorboard, we will first see how to display the Tensorboard dashboard and discuss the process of logging in the next section.\n",
    "\n",
    "In this section, we will see \n",
    "\n",
    "1. How to display the TensorBoard dashboard using a notebook and \n",
    "1. Run TensorBoard in a web browser\n",
    "\n",
    "Make sure you have TensorBoard installed. In your python or conda environment run the following command:\n",
    "\n",
    "```\n",
    "tensorboard --version\n",
    "```\n",
    "\n",
    "**If not installed, here are links to install TensorBoard in [python-environment](https://pypi.org/project/tensorboard/) and [conda-environment](https://anaconda.org/conda-forge/tensorboard).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">Tensorboard Logs</font>\n",
    "To display TensorBoard Dashboard, we need logs compatible with TensorBoard. To make it a bit easier to follow, we are sharing a folder which contains the logs of an experiment we had done. We will go over the contents of the log folder and see how to use this for displaying them on Tensorboard. \n",
    "\n",
    "Let us first download and extract the logs folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget \"https://www.dropbox.com/sh/AA8xGsR4WjHRuKVdFKR4c1la?dl=1\" -O sample_logs.zip\n",
    "\n",
    "#!unzip -q sample_logs.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Screenshot from 2020-10-14 10-37-45.png\" width=900>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">What is there in the Logs? </font>\n",
    "Let us examine the folder structure and the files/folders that are present in the logs directory. We will assume that the logs directory is `logs_fashion_mnist`. We don't need to go into much details of the logs directory. But we will briefly understand the folder structure of the logs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_regularization  regularization\r\n"
     ]
    }
   ],
   "source": [
    "!ls logs_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We had done two experiments for `no_regularization` & `regularization`. So, the logs folder has 2 folders. Let us see the logs of one experiment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mlogs_fashion_mnist/regularization\u001b[00m\r\n",
      "├── \u001b[01;34m00000\u001b[00m\r\n",
      "│   └── \u001b[01;34mdefault\u001b[00m\r\n",
      "│       ├── \u001b[01;32mmetadata.tsv\u001b[00m\r\n",
      "│       ├── \u001b[01;32msprite.png\u001b[00m\r\n",
      "│       └── \u001b[01;32mtensors.tsv\u001b[00m\r\n",
      "├── \u001b[01;34mAccuracy_train-val_train\u001b[00m\r\n",
      "│   └── \u001b[01;32mevents.out.tfevents.1582146167.pc.18717.3\u001b[00m\r\n",
      "├── \u001b[01;34mAccuracy_train-val_validation\u001b[00m\r\n",
      "│   └── \u001b[01;32mevents.out.tfevents.1582146167.pc.18717.4\u001b[00m\r\n",
      "├── \u001b[01;32mevents.out.tfevents.1582146148.pc.18717.0\u001b[00m\r\n",
      "├── \u001b[01;34mLoss_train-val_train\u001b[00m\r\n",
      "│   └── \u001b[01;32mevents.out.tfevents.1582146167.pc.18717.1\u001b[00m\r\n",
      "├── \u001b[01;34mLoss_train-val_validation\u001b[00m\r\n",
      "│   └── \u001b[01;32mevents.out.tfevents.1582146167.pc.18717.2\u001b[00m\r\n",
      "└── \u001b[01;32mprojector_config.pbtxt\u001b[00m\r\n",
      "\r\n",
      "6 directories, 9 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree logs_file_name/regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above folder is created when you save any metrics to the tensorboard summarywriter. \n",
    "\n",
    "The above shows the structure of the tensorboard logs. The logs are saved as tfevents data files ( e.g. events.out.tfevents.1582146148.pc.18717.0 ) and are also called summary data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:blue\">1. TensorBoard Dashboard in the Notebook</font>\n",
    "\n",
    "Run the following command in a notebook cell:\n",
    "\n",
    "```\n",
    "# This will launch Tensorboard\n",
    "%load_ext tensorboard\n",
    "\n",
    "# logs folder path\n",
    "%tensorboard --logdir=logs_fashion_mnist    \n",
    "```\n",
    "\n",
    "**You will get an output which will be similar to the following:**\n",
    "\n",
    "<img src=\"https://www.learnopencv.com/wp-content/uploads/2020/02/c3_w5_tensorboard_notepad.png\" width=900>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you want to reload the Dashboard, use the command `%reload_ext tensorboard`**\n",
    "```    \n",
    "# To reload tensorBoard\n",
    "%reload_ext tensorboard\n",
    "\n",
    "# logs folder path\n",
    "%tensorboard --logdir=logs_fashion_mnist  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:blue\">2. TensorBoard Dashboard on Web Browser</font>\n",
    "\n",
    "We can Display Tensorboard on Web Browser using any of the following ways:\n",
    "\n",
    "1. Running it on the local system\n",
    "\n",
    "2. Running it on a remote system.\n",
    "\n",
    "**Let's see how it is done**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:green\">2.1. Running Tensorboard on the Local System</font>\n",
    "\n",
    "**Run the following command on the local system:**\n",
    "\n",
    "```\n",
    "tensorboard --logdir logs_fashion_mnist --port default\n",
    "```\n",
    "<font >You will get similiar output as shown below</font>\n",
    "\n",
    "\n",
    "```\n",
    "TensorFlow installation not found - running with reduced feature set.\n",
    "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
    "TensorBoard 2.0.1 at http://localhost:6006/ (Press CTRL+C to quit)\n",
    "```\n",
    "\n",
    "**Copy the link from the output (in this case it is `http://localhost:6006/`) and paste in your browser**\n",
    " \n",
    "\n",
    "**It will look similar to the follwong:**\n",
    "\n",
    "<img src=\"https://www.learnopencv.com/wp-content/uploads/2020/02/c3-w-4-tensorboard_local.png\" width=900>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:green\">2.2. Running Tensorboard on a remote System</font>\n",
    "\n",
    "**Run the following command on the remote system:**\n",
    "\n",
    "\n",
    "```\n",
    "tensorboard --logdir logs_fashion_mnist --port default\n",
    "```\n",
    "\n",
    "**The Output will be similar to as shown below**\n",
    "\n",
    "```\n",
    "TensorFlow installation not found - running with reduced feature set.\n",
    "TensorBoard 1.15.0 at http://remote-ip-address:6006/ (Press CTRL+C to quit)\n",
    "```\n",
    "\n",
    "**Now the question is, can you open the above link in the browser?**\n",
    "\n",
    "No, because it is not in public domain. \n",
    "\n",
    "But you know the public IP and password of the remote machine (or your local machine ssh key might be already added to the remote machine). So by using shh port forwarding mechanism, a remote machine port can be tunneled to the local machine port. \n",
    "\n",
    "**We can use the following command to forward the remote port to the local machine port:**\n",
    "\n",
    "```\n",
    "ssh -N -f -L localhost:7006:remote-ip-address:6006 username@public_ip\n",
    "```\n",
    "\n",
    "The above command will forward `remote-ip-address:6006` to `localhost:7006`.\n",
    "\n",
    "**Open the link `localhost:7006` in a browser.**\n",
    "\n",
    "**It should look similar to the following:**\n",
    "\n",
    "<img src=\"https://www.learnopencv.com/wp-content/uploads/2020/02/c3-w3-tensorboard_remote.png\" width=900>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">How to add TensorBoard logs</font>\n",
    "\n",
    "In this unit we will learn how to add logs to Tensorboard.\n",
    "\n",
    "**We will add the following logs to the TensorBoard**\n",
    "\n",
    "1. Scalars: We can add loss, accuracy etc as scalars.\n",
    "\n",
    "2. Images: We can add plots or figures.\n",
    "\n",
    "3. Graphs: We can add a network graph and its input-output. \n",
    "\n",
    "4. Histograms: We can add n-d array to get its histogram. For example, in each epoch we can add convolution weights.\n",
    "\n",
    "5. PR Curves: We can add prediction probability and labels to get precision vs recall curves.\n",
    "\n",
    "6. Projector: We can add sampled training data to get its embeddings. \n",
    "\n",
    "\n",
    "**We will use two experiments of the regularization notebook**\n",
    "\n",
    "1. Medium-sized model, training without regularization.\n",
    "\n",
    "2. Medium-sized model, training with regularization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:Blue\">1. TensorBoard Dashboard</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "# %reload_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir=logs_of_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">2. Training Utils</font>\n",
    "\n",
    "## <font style=\"color:green\">2.1. Get Fashion MNIST data</font>\n",
    "\n",
    "\n",
    "\n",
    "## <font style=\"color:magenta\">i. Projector in TensorBoard</font>\n",
    "\n",
    "We can add sampled training data to get its embeddings (e.g. PCA, T-SNE, etc.).\n",
    "\n",
    "```\n",
    "SummaryWriter.add_embedding(mat, metadata=None, label_img=None, global_step=None, tag='default', metadata_header=None)\n",
    "```\n",
    "\n",
    "**Parameters:**\n",
    "\n",
    "- **mat** (`torch.Tensor` or `numpy.array`) – A matrix in which each row is the feature vector of the data point. For example, if we have n images of `3` channel (colored) with width `W`and height `H`, then the data shape will be `n x 3 x H x W`. So the mat input should be `n x 3 * H * W`.\n",
    "\n",
    "- **metadata** (`list`) – A list of labels of which each element will be converted to string\n",
    "\n",
    "- **label_img** (`torch.Tensor`) – Images correspond to each data point\n",
    "\n",
    "- **global_step** (`python:int`) – Global step value to record\n",
    "\n",
    "- **tag** (`string`) – Name for the embedding\n",
    "\n",
    "Get details [here](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_embedding)\n",
    "\n",
    "\n",
    "Function **`add_data_embedings`** in below cell samples add n-datapoints from the dataset and data to TensorBoard.\n",
    "\n",
    "\n",
    "**PROJECTOR** tab will look similar to the following after changing colored as labels:\n",
    "\n",
    "\n",
    "<img src=\"https://www.learnopencv.com/wp-content/uploads/2020/02/w3-w4-projrctor-tensorboard.png\" width=900>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">2.2. System Configuration</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">2.3. Training Configuration</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">2.4. System Setup</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">2.5. Predictions</font>`\n",
    "\n",
    "## <font style=\"color:magenta\">ii. PR Curves in TensorBoard</font>\n",
    "\n",
    "Precision-recall curve tells us about the model’s performance under different threshold settings. With this function we have to provide the ground truth labeling (T/F) and prediction confidence (usually the output of the model) for each target. The TensorBoard UI will let you choose the threshold interactively.\n",
    "```\n",
    "SummaryWriter.add_pr_curve(tag, labels, predictions, global_step=None, num_thresholds=127, weights=None, walltime=None)\n",
    "```\n",
    "\n",
    "\n",
    "**Parameters:**\n",
    "\n",
    "- **tag** (`string`) – Data identifier\n",
    "\n",
    "- **labels** (`torch.Tensor`, `numpy.array`, or `string/blobname`) – Ground truth data. Binary label for each element.\n",
    "\n",
    "- **predictions** (`torch.Tensor`, `numpy.array`, or `string/blobname`) – The probability that an element be classified as true. Value should in [0, 1]\n",
    "\n",
    "- **global_step** (`python:int`) – Global step value to record\n",
    "\n",
    "- **num_thresholds** (`python:int`) – Number of thresholds used to draw the curve.\n",
    "\n",
    "- **walltime** (`python:float`) – Optional override default walltime (time.time()) in seconds.\n",
    "\n",
    "Get more details [here](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_pr_curve).\n",
    "\n",
    "Function **`add_pr_curves_to_tensorboard`**, gets target and prediction probabilities from the function `get_target_and_prob` and pass it to `SummaryWriter.add_pr_curve` to get precision-recall curve in TensorBoard.\n",
    "\n",
    "**PR CURVES** tab will look similar to the following:\n",
    "\n",
    "<img src=\"https://www.learnopencv.com/wp-content/uploads/2020/02/c3-w4-prcurves-tensorboard.png\" width=900>\n",
    "\n",
    "\n",
    "## <font style=\"color:magenta\">iii. Images in TensorBoard</font>\n",
    "\n",
    "**Add image data to the summary.**\n",
    "\n",
    "```\n",
    "SummaryWriter.add_image(tag, img_tensor, global_step=None, walltime=None, dataformats='CHW')\n",
    "```\n",
    "\n",
    "**Parameters:**\n",
    "\n",
    "- **tag** (`string`) – Data identifier\n",
    "\n",
    "- **img_tensor** (`torch.Tensor`, `numpy.array`, or `string/blobname`) – Image data. e.g Matplotlib fig, images etc.\n",
    "\n",
    "- **global_step** (`python:int`) – Global step value to record\n",
    "\n",
    "- **walltime** (`python:float`) – Optional override default walltime (`time.time()`) in seconds \n",
    "\n",
    "Find details [here](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_image).\n",
    "\n",
    "In the function **`add_wrong_prediction_to_tensorboard`**, we will find wrong predictions, plot as a figure and then add this figure to TensorBoard.\n",
    "\n",
    "The following is a sample image, which is added to TensorBoard.\n",
    "\n",
    "<img src=\"https://www.learnopencv.com/wp-content/uploads/2020/02/c3-w4-images-tensorboard.png\" width=900>\n",
    "\n",
    "\n",
    "\n",
    "## <font style=\"color:magenta\">iv. Histogram in TensorBoard</font>\n",
    "\n",
    "**Add histogram to summary.**\n",
    "\n",
    "```\n",
    "SummaryWriter.add_histogram(tag, values, global_step=None, bins='tensorflow', walltime=None, max_bins=None)\n",
    "```\n",
    "\n",
    "**Parameters:**\n",
    "\n",
    "- **tag** (`string`) – Data identifier\n",
    "\n",
    "- **values** (`torch.Tensor`, `numpy.array`, or `string/blobname`) – Values to build histogram\n",
    "\n",
    "- **global_step** (`python:int`) – Global step value to record\n",
    "\n",
    "- **bins** (`string`) – One of {‘tensorflow’,’auto’, ‘fd’, …}. This determines how the bins are made. You can find other options in: https://docs.scipy.org/doc/numpy/reference/generated/numpy.histogram.html\n",
    "\n",
    "- **walltime** (`python:float`) – Optional override default walltime (`time.time()`) seconds after epoch of event\n",
    "\n",
    "Find details [here](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_histogram).\n",
    "\n",
    "In the function **`add_model_weights_as_histogram`**, we are iterating through named parameters and plotting as a histogram. \n",
    "\n",
    "**The followings are the histogram plots for first layer CNN filters for no-regularization and regularization for all epochs:**\n",
    "\n",
    "---\n",
    "\n",
    "<table><tr>\n",
    "<td><img src=\"https://www.learnopencv.com/wp-content/uploads/2020/02/c3-w4-no-reg-tensorboard.png\" alt=\"Drawing\" style=\"width: 500px;\"></td>\n",
    "<td> <img src=\"https://www.learnopencv.com/wp-content/uploads/2020/02/c3-w4-reg-tensorboard.png\" alt=\"Drawing\" style=\"width: 5\n",
    "    00px;\"></td>\n",
    "</tr></table>\n",
    "\n",
    "---\n",
    "    \n",
    "From the histogram, we can observe that the average weight of no-regularization is lower than regularization.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## <font style=\"color:magenta\">v. Graph in TensorBoard</font>\n",
    "\n",
    "**Add network graph and input shape to the summary.**\n",
    "\n",
    "```\n",
    "SummaryWriter.add_graph(model, input_to_model=None, verbose=False)\n",
    "```\n",
    "\n",
    "**Parameters:**\n",
    "\n",
    "- **model** (`nn.modules`) – PyTorch model\n",
    "\n",
    "- **input_to_model** (`tensor`) – Input tensor.\n",
    "\n",
    "In the function **`add_network_graph_tensorboard`**, we add a neural network graph and it's inputs.\n",
    "\n",
    "**The followings are images of the graph and it's inputs**\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<table><tr>\n",
    "<td><img src=\"https://www.learnopencv.com/wp-content/uploads/2020/02/c3-w4-graph-tensorboard.png\" alt=\"Drawing\" style=\"width: 500px;\"></td>\n",
    "<td> <img src=\"https://www.learnopencv.com/wp-content/uploads/2020/02/c3-w4-inputs-tensorboard.png\" alt=\"Drawing\" style=\"width: 5\n",
    "    00px;\"></td>\n",
    "</tr></table>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## <font style=\"color:green\">2.8. Main Function for Training and Validation</font>\n",
    "\n",
    "\n",
    "\n",
    "## <font style=\"color:magenta\">vi. Scalar In TensorBoard</font>\n",
    "\n",
    "**Add scalar data to the summary. e.g. loss, accuracy etc.**\n",
    "\n",
    "```\n",
    "SummaryWriter.add_scalar(tag, scalar_value, global_step=None, walltime=None)\n",
    "```\n",
    "\n",
    "**Parameters:**\n",
    "\n",
    "- **tag** (`string`) – Data identifier\n",
    "\n",
    "- **scalar_value** (`python:float` or `string/blobname`) – Value to save\n",
    "\n",
    "- **global_step** (`python:int`) – Global step value to record\n",
    "\n",
    "- **walltime** (`python:float`) – Optional override default walltime (`time.time()`) in seconds.\n",
    "\n",
    "Get details [here](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_scalar).\n",
    "\n",
    "In the **`main`** function, we add loss, accuracy etc. as a scalar. \n",
    "\n",
    "The following is a sample plot of scalar (validation accuracy): \n",
    "\n",
    "<img src=\"https://www.learnopencv.com/wp-content/uploads/2020/02/c3-w4-scalar-tensorboard.png\">\n",
    "\n",
    "\n",
    "## <font style=\"color:magenta\">vii. Scalars in TensorBoard</font>\n",
    "\n",
    "**Adds many scalar data to the summary. e.g. validation and train loss together.**\n",
    "\n",
    "<font style=\"color:red\">Note that this function also keeps logged scalars in memory. In extreme case it explodes your RAM.</font>\n",
    "\n",
    "```\n",
    "SummaryWriter.add_scalars(main_tag, tag_scalar_dict, global_step=None, walltime=None)\n",
    "```\n",
    "\n",
    "**Parameters:**\n",
    "\n",
    "- **main_tag** (`string`) – The parent name for the tags\n",
    "\n",
    "- **tag_scalar_dict** (`dict`) – Key-value pair storing the tag and the corresponding values. e.g `dict`\n",
    "\n",
    "- **global_step** (`python:int`) – Global step value to record\n",
    "\n",
    "- **walltime** (`python:float`) – Optional override default walltime (`time.time()`) in seconds.\n",
    "\n",
    "Get details [here](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_scalars).\n",
    "\n",
    "In the **`main`** function, We will add loss and accuracy of training and validation simaltanously as scalars. \n",
    "\n",
    "The following is a sample plot of scalar (training and validation loss): \n",
    "\n",
    "<img src=\"https://www.learnopencv.com/wp-content/uploads/2020/02/c3-w4-scalars-tensorboard.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:Blue\">References</font>\n",
    "\n",
    "- https://pytorch.org/docs/stable/tensorboard.html\n",
    "\n",
    "- https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
